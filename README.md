# Awesome Language Models Interpretability 

This GitHub will list several papers that align with one of my research focuses. This repo will be occasionally updated as i found interesting stuffs.

## Survey
- [A Primer on the Inner Workings of Transformer-based Language Models.](https://arxiv.org/pdf/2405.00208)

## Interpretability Approaches
- [How do Large Language Models Handle Multilingualism?](https://arxiv.org/pdf/2402.18815)
- [The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models](https://openreview.net/pdf?id=SQGUDc9tC8)
- [interpreting GPT: the logit lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)
- [DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers](https://arxiv.org/abs/2310.03686)
- [Eliciting Latent Predictions from Transformers with the Tuned Lens](https://arxiv.org/abs/2303.08112)
- [Open Source Automated Interpretability for Sparse Autoencoder Features](https://www.lesswrong.com/posts/AhG3RJ6F5KvmKmAkd/open-source-automated-interpretability-for-sparse)
- [On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons](https://aclanthology.org/2024.naacl-long.384/)
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features)
- [Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps](https://arxiv.org/abs/2302.00456)
- [CausalGym](https://arxiv.org/pdf/2402.12560)
- [Probing the Emergence of Cross-lingual Alignment during LLM Training](https://arxiv.org/abs/2406.13229)
- [Sparse Autoencoders Reveal Universal Feature Spaces Across Large Language Models](http://arxiv.org/abs/2410.06981)
- [Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small](https://arxiv.org/abs/2409.04478)
- [Influence functions - why, what and how](https://www.lesswrong.com/posts/sYeZvofqbWJDrXEHM/influence-functions-why-what-and-how)
- [Information Flow Routes:
Automatically Interpreting Language Models at Scale](https://arxiv.org/pdf/2403.00824)

## Knowledge Editing
- [Locating and Editing Factual Associations in GPT](https://arxiv.org/abs/2202.05262)
- [Mass Editing Memory in a Transformer](https://arxiv.org/pdf/2210.07229)
- [Cross-Lingual Knowledge Editing in Large Language Models](https://arxiv.org/html/2309.08952v2)
- [Locating and Editing Factual Associations in Mamba.](https://arxiv.org/pdf/2404.03646)
  
## Capabilites of Language Models
- [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://arxiv.org/abs/2402.11655)
- [How do Language Models Bind Entities in Context?](https://arxiv.org/abs/2310.17191)
- [Language Models as Knowledge Bases?](https://arxiv.org/abs/1909.01066)
- [Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models](https://arxiv.org/abs/2102.00894)
- [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://aclanthology.org/2023.emnlp-main.658.pdf)

## Tutorials
- [EACL'24 Transformer-specific Interpretability](https://github.com/interpretingdl/eacl2024_transformer_interpretability_tutorial)