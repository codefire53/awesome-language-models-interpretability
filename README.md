# Awesome Language Models Interpretability 

This GitHub will list several papers that align with one of my research focuses. This repo will be occasionally updated as i found interesting stuffs.

## Survey
- [A Primer on the Inner Workings of Transformer-based Language Models.](https://arxiv.org/pdf/2405.00208)

## Mechanistics Interpretability
- [How do Large Language Models Handle Multilingualism?](https://arxiv.org/pdf/2402.18815)
- [The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models](https://openreview.net/pdf?id=SQGUDc9tC8)
- [interpreting GPT: the logit lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)
- [DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers](https://arxiv.org/abs/2310.03686)
- [Eliciting Latent Predictions from Transformers with the Tuned Lens](https://arxiv.org/abs/2303.08112)
- [Open Source Automated Interpretability for Sparse Autoencoder Features](https://www.lesswrong.com/posts/AhG3RJ6F5KvmKmAkd/open-source-automated-interpretability-for-sparse)
- [On the Multilingual Ability of Decoder-based Pre-trained Language Models: Finding and Controlling Language-Specific Neurons](https://aclanthology.org/2024.naacl-long.384/)
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features)

## Knowledge Editing
- [Locating and Editing Factual Associations in GPT](https://arxiv.org/abs/2202.05262)
- [Mass Editing Memory in a Transformer](https://arxiv.org/pdf/2210.07229)
- [Cross-Lingual Knowledge Editing in Large Language Models](https://arxiv.org/html/2309.08952v2)
- [Locating and Editing Factual Associations in Mamba.](https://arxiv.org/pdf/2404.03646)
  
## Capabilites of Language Models
- [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://arxiv.org/abs/2402.11655)
- [How do Language Models Bind Entities in Context?](https://arxiv.org/abs/2310.17191)
- [Language Models as Knowledge Bases?](https://arxiv.org/abs/1909.01066)
- [Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models](https://arxiv.org/abs/2102.00894)
- [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://aclanthology.org/2023.emnlp-main.658.pdf)